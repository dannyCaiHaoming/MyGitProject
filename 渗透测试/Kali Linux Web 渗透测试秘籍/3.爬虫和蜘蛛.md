### 简介

渗透测试可以通过多种途径完成，例如黑白灰盒。

我们打算采取黑盒测试方式，因为它涉及到外部攻击者用于获取足够信息的所有步骤，以便入侵应用或服务器的特定功能。

作为每个 Web 渗透测试中侦查阶段的一部分，我们需要浏览器每个包含在网页中的链接，并跟踪它展示的每个文件。有一些工具能够帮助我们自动和以及加速完成这个任务，它们叫做 Web 爬虫或蜘蛛。这些工具通过跟随所有到外部文件的链接和引用，有的时候会填充表单并将它们发送到服务器，保存所有请求和响应来浏览网页，从而提供给我们离线分析它们的机会。





### 1. 使用Wget为离线分析下载网页

wget是GNU项目的一部分，它能够递归为离线浏览下载网页，包括连接转换和下载非HTML文件。

1. 递归下载应用中所有文件并保存到相应的目录中

```shell
wget -r -P 下载路径 ip地址
```

- `-r`:递归网页
- `-l`:设定递归深度
- `-P`:设置目录前缀,这是Wget会开始保存下载内容的目录
- `-p`:下载页面所需的所有图像



##### 工作原理

像之前提到的那样，Wget 是个为下载 HTTP 内容创建的工具。通过`-r`参数，我们可以使其递归下载，这会按照它所下载的每个页面的所有连接，并同样下载它





### 2. HTTrack为离线分析下载页面

> 它允许你从互联网下载 WWW 站点到本地目录中，递归构建所有目录、从服务器获得 HTML、图像，和其它文件到你的计算机中。

##### 操作步骤

1. 使用httrack下载URL

```shell
httrack ip地址
```



##### 工作原理

HTTrack 创建站点的完整静态副本，这意味着所有动态内容，例如用户输入的响应，都不会有效。

- `cookies.txt`包含用于下载站点的cookie信息
- `hts-cache`目录包含爬虫检测到的文件列表，
- `hts-log.txt`包含错误、警告和其它爬取或下载站点期间的信息
- `index.html`文件重定向到副本的原始主页







### 3. 使用ZAP蜘蛛

在我们的计算机中将完整的站点下载到目录给予我们信息的静态副本，这意味着我们拥有了不同请求产生的输出，但是我们没有服务器的请求或响应状态。为了拥有这种信息的记录，我们需要使用蜘蛛，就像 OWASP ZAP 中集成的这个。



##### 操作步骤

1. 设置zap和浏览器代理
2. 浏览器访问目标地址，zap开始`Attack|Spider`
3. 从结果中，能查看到每个请求的请求和响应参数



##### 工作原理

就像任何其它爬虫那样，ZAP 的蜘蛛跟随它找到的每个链接，位于每个包含请求范围以及其中的链接中的页面上。此外，蜘蛛会跟随表单响应、重定向和包含在`robots.txt`和`sitemap.xml`文件中的 URL。之后它会为之后分析和使用储存所有请求和响应、





### 4. 使用Burp Suite爬取站点



##### 工作原理

Burp 的蜘蛛遵循和其它蜘蛛相同的方式，但是它的行为有一些不同，我们可以让它在我们浏览站点的时候运行，它会添加我们跟随（匹配范围定义）的链接到爬取队列中。

就像 ZAP 那样，我们可以使用 Burp 的爬取结果来执行任何操作。我们可以执行任何请求，例如扫描（如果我们拥有付费版）、重放、比较、模糊测试、在浏览器中查看，以及其它。



##### 操作步骤

1. 设置burp代理，配置浏览器代理
2. 浏览器访问目标地址
3. 在burp中对目标地址的目标文件夹激活`Spider this branch`



### 5. 使用Burp重放器重发请求



##### 工作原理

Burp 的重放器允许我们手动为相同的 HTTP 请求测试不同的输入和场景，并且分析服务器提供的响应。这在测试漏洞的时候非常实用，因为测试者可以了解应用如何对多种所提供的输入反应，以及从而识别或利用设计、编程或配置中的可能缺陷。





### 6. 使用WebScarab

WebScarab 是另一个 Web 代理，拥有让渗透测试者感兴趣的特性。这个秘籍中，我们会使用它来爬取网站。



##### 操作步骤

1. 配置浏览器代理，注意端口为8008
2. 浏览目标地址
3. 在webscarab中选取目标文件夹，选择`Spider tree`



### 7. 从爬取结果中识别相关文件和目录

我们已经爬取了应用的完整目录，并且拥有了被引用文件和目录的完整列表。下一步地然是识别这些文件哪个包含相关信息，或者是更可能发现漏洞的机会。

这篇不仅仅是个秘籍，更是用于文件和目录的常见名称、前后缀的总结，它们通常给渗透测试者提供有价值的信息，或者是可能导致整个系统沦陷的漏洞利用。



##### 操作步骤

1. 寻找登录和注册页面，通过以下名称例子，目的性更强：

- Account
- Auth
- Login
- Logon
- Registration
- Register
- Signup
- Signin

2. 用户名、密码，密码恢复页面

- Change
- Forgot
- lost-password
- Password
- Recover
- Reset

3. 需要识别是否存在应用的管理员部分，这里有一组功能可能允许我们执行高权限的操作

- Admin
- Config
- Manager
- Root

4. 录是内容管理系统（CMS）的管理员、数据库或应用服务器之一

- Admin-console
- Adminer
- Administrator
- Couch
- Manager
- Mylittleadmin
- PhpMyAdmin
- SqlWebAdmin
- Wp-admin

5. 应用的测试和开发版通常没有保护，并且比最终发行版更容易存在漏洞，所以它们在我们搜索缺陷的时候是个很好的目标

- Alpha
- Beta
- Dev
- Development
- QA
- Test

6. Web 服务器的信息和配置文件如下

- config.xml
- info
- phpinfo
- server-status
- web.config

7. 此外，所有在`robots.txt`中标记为`Disallow`的目录和文件可能非常实用。